## üé¨ Clasificaci√≥n de sentimientos en rese√±as de pel√≠culas con Machine Learning

### üìå Introducci√≥n

Este proyecto forma parte del desarrollo de **Film Junky Union**, una comunidad para aficionados al cine cl√°sico. El objetivo es entrenar un modelo de machine learning capaz de **detectar autom√°ticamente cr√≠ticas negativas en rese√±as de pel√≠culas**, utilizando datos de IMDB.  

El reto consiste en construir un clasificador de sentimientos que distinga entre rese√±as positivas y negativas, alcanzando un **F1-score m√≠nimo de 0.85**.

---

### üéØ Objetivo

- Analizar un conjunto de datos de rese√±as de pel√≠culas.  
- Preprocesar el texto para su representaci√≥n en modelos de machine learning.  
- Entrenar y comparar diferentes algoritmos de clasificaci√≥n.  
- Evaluar el rendimiento de los modelos utilizando m√©tricas como *accuracy*, *precision*, *recall* y *F1-score*.  
- Seleccionar el modelo final que cumpla con el umbral de desempe√±o (F1 ‚â• 0.85).  

---

### üß† Habilidades t√©cnicas demostradas

Este proyecto refleja competencias clave en **procesamiento de lenguaje natural (NLP)** y machine learning:

- **An√°lisis exploratorio de datos (EDA)**: revisi√≥n de distribuci√≥n de rese√±as y longitud de textos.  
- **Limpieza y transformaci√≥n de texto**: tokenizaci√≥n, stopwords, lematizaci√≥n y vectorizaci√≥n (TF-IDF / Bag of Words).  
- **Modelado predictivo**: entrenamiento de clasificadores como *Logistic Regression* y *LightGBM*.
- **Deep Learning aplicado a NLP**: uso de **PyTorch** y la librer√≠a **Transformers** con **BERT**.  
- **Evaluaci√≥n de modelos**: m√©tricas como *accuracy*, *recall*, *precision* y *F1-score*.   
- **Documentaci√≥n clara y reproducible**: flujo de trabajo modular en notebooks de Jupyter.  

---

### üõ†Ô∏è Tecnolog√≠as y herramientas utilizadas

- **Python**  
- **pandas** y **NumPy**: manejo y transformaci√≥n de datos.  
- **scikit-learn**: modelado y evaluaci√≥n.  
- **NLTK / spaCy**: preprocesamiento de texto.  
- **matplotlib / seaborn**: visualizaci√≥n de datos y m√©tricas.  
- **tqdm**: seguimiento de procesos iterativos.  

---

### ‚úÖ Resultados y conclusiones

- Se entrenaron y compararon varios modelos de clasificaci√≥n de texto.  
- El modelo seleccionado fue el modelo 1 (NLTK, TF-IDF y LR) con un valor de **F1 de 0.88**, cumpliendo con el objetivo establecido.  
- Se recomendo evaluar el modelo 4 (BERT y LightGBM) haciendo uso de m√°s datos en un ambiente con GPU.

---

### üìà Posibles mejoras futuras

- Probar modelos avanzados como **redes neuronales**.  
- Implementar un pipeline con entrenamiento en GPU para **BERT**.  
- Desplegar el modelo en una API para clasificaci√≥n en tiempo real.    

---

### üë®‚Äçüíª Autor

**Andr√©s Calvete**  
Cient√≠fico de Datos Junior  
[LinkedIn](https://www.linkedin.com/in/andrescalvete/)  
ascalvete@hotmail.com
